# Bank Credit Card Fraud Detection with MOA and Explainability ğŸ”ğŸ’³

This project focuses on detecting credit card fraud using a Mixture of Agents (MOA) model, combining machine learning with explainability features provided by a Large Language Model (LLM). The goal is to enhance transparency and provide understandable insights into fraud detection results.

## ğŸš€ Features
- **Fraud Detection Model**: A MOA model trained to identify fraudulent transactions.
- **Data Preparation**: Preprocessing pipeline that normalizes and handles missing values in the data.
- **Explainability**: Integration with an LLM to generate clear, human-readable explanations for each prediction, ensuring transparency in decision-making.
- **Streamlit Interface**: User-friendly interface to input transaction data and view predictions with detailed explanations.

## ğŸ“‚ Project Structure
```
â”œâ”€â”€ README.md
â”œâ”€â”€ assets
â”œâ”€â”€ bankcreditcardfraud
â”‚Â Â  â””â”€â”€ __init__.py
â”œâ”€â”€ data
â”‚Â Â  â”œâ”€â”€ processed_data
â”‚Â Â  â”œâ”€â”€ raw_data
â”‚Â Â  â”œâ”€â”€ test
â”‚Â Â  â”œâ”€â”€ train
â”‚Â Â  â””â”€â”€ val
â”œâ”€â”€ docs
â”œâ”€â”€ models
â”‚Â Â  â”œâ”€â”€ data_preparation.pkl
â”‚Â Â  â””â”€â”€ moa_model
â”œâ”€â”€ notebooks
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ src
â”‚Â Â  â”œâ”€â”€ features
â”‚Â Â  â”œâ”€â”€ main.py
â”‚Â Â  â”œâ”€â”€ model
â”‚Â Â  â””â”€â”€ utils
â””â”€â”€ tests
```

## ğŸ›  Installation & Usage
Clone the Repository:


```bash
git clone https://github.com/yourusername/Bank-CreditCard-MOA-Explicability.git
cd Bank-CreditCard-MOA-Explicability
```

Set up the Environment:


Install the required Python dependencies with poetry or pip.

```bash
poetry install
```

Prepare the Dataset:

Place your dataset (creditcard.csv) in the data/raw_data/ directory.
Run the Streamlit App:

```bash
streamlit run app.py
```

Environment Variables:

Add your API key for the LLM in a .env file:

```bash
TOGETHER_API_KEY=your_api_key
```

ğŸ“Š Model and Data Preprocessing
The project uses StandardScaler for data normalization and SMOTE to balance the dataset.
The model is trained to classify transactions as fraudulent or not, with detailed explanations generated for each result.

ğŸ§  Explainability
Using the TogetherAI LLM, this project adds human-readable insights into each prediction, helping users understand why a transaction is classified as fraudulent or legitimate.


ğŸ¤– Technology Stack
Python ğŸ
scikit-learn for machine learning
MLflow for model management
TogetherAI for explainability
Streamlit for the user interface
Poetry for dependency management

ğŸŒŸ Contributing
Feel free to open issues or pull requests to enhance the project.

âš–ï¸ License
This project is licensed under the MIT License. See the LICENSE file for more information.


